{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Data Ingestion Pipeline"
      ],
      "metadata": {
        "id": "oERHyDCI1RUU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Document Parsing"
      ],
      "metadata": {
        "id": "Gcyhxul94eOk"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2417cb7",
        "outputId": "d7243f5f-6cb4-424b-fcaa-db0cabfe17fd"
      },
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install langchain langchain-core langchain-community pypdf pymupdf sentence-transformers faiss-cpu chromadb langchain-groq python-dotenv typesense langchain_openai langgraph"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.2.0)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-6.5.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.26.7-cp310-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.13.2-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.6 kB)\n",
            "Collecting chromadb\n",
            "  Downloading chromadb-1.4.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n",
            "Collecting langchain-groq\n",
            "  Downloading langchain_groq-1.1.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Collecting typesense\n",
            "  Downloading typesense-1.3.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-1.1.6-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.12/dist-packages (1.0.5)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.4.59)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.12.0)\n",
            "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community)\n",
            "  Downloading langchain_classic-1.0.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.45)\n",
            "Collecting requests<3.0.0,>=2.32.5 (from langchain-community)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.2)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cpu)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n",
            "Collecting build>=1.0.3 (from chromadb)\n",
            "  Downloading build-1.3.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting pybase64>=1.4.1 (from chromadb)\n",
            "  Downloading pybase64-1.4.3-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.38.0)\n",
            "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.39.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.22.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.76.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.20.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-34.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.2.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb) (3.11.5)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.25.1)\n",
            "Collecting groq<1.0.0,>=0.30.0 (from langchain-groq)\n",
            "  Downloading groq-0.37.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting langchain-core\n",
            "  Downloading langchain_core-1.2.5-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (2.12.0)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (0.12.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph) (1.0.5)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.3.0)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.30.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.43.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Collecting urllib3<2.4.0,>=1.24.2 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Collecting langchain-text-splitters<2.0.0,>=1.1.0 (from langchain-classic<2.0.0,>=1.0.0->langchain-community)\n",
            "  Downloading langchain_text_splitters-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph) (1.12.1)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.9.23)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (0.12.0)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.72.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.39.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.39.1-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.39.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.39.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.39.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.39.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.60b1 (from opentelemetry-sdk>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.3.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain_openai) (2025.11.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (6.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-6.5.0-py3-none-any.whl (329 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m329.6/329.6 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pymupdf-1.26.7-cp310-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.13.2-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chromadb-1.4.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.7/21.7 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_groq-1.1.1-py3-none-any.whl (19 kB)\n",
            "Downloading typesense-1.3.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.3/84.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-1.1.6-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.7/84.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-1.2.5-py3-none-any.whl (484 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m484.9/484.9 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.3.0-py3-none-any.whl (23 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading groq-0.37.1-py3-none-any.whl (137 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-34.1.0-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_classic-1.0.1-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m99.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.39.1-py3-none-any.whl (19 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.39.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.39.1-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.39.1-py3-none-any.whl (132 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.39.1-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl (219 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.0/220.0 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybase64-1.4.3-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (517 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-1.1.0-py3-none-any.whl (34 kB)\n",
            "Downloading marshmallow-3.26.2-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m110.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (456 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=924a72b88770c2bfab84ea45913425e0ce9df09a760350975130b4fffb965621\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, durationpy, uvloop, urllib3, pyproject_hooks, pypdf, pymupdf, pybase64, opentelemetry-proto, mypy-extensions, marshmallow, humanfriendly, httptools, faiss-cpu, bcrypt, backoff, watchfiles, typing-inspect, requests, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, build, typesense, posthog, opentelemetry-semantic-conventions, onnxruntime, groq, dataclasses-json, opentelemetry-sdk, kubernetes, opentelemetry-exporter-otlp-proto-grpc, langchain-core, langchain-text-splitters, langchain_openai, langchain-groq, chromadb, langchain-classic, langchain-community\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "  Attempting uninstall: opentelemetry-proto\n",
            "    Found existing installation: opentelemetry-proto 1.37.0\n",
            "    Uninstalling opentelemetry-proto-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-proto-1.37.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: opentelemetry-exporter-otlp-proto-common\n",
            "    Found existing installation: opentelemetry-exporter-otlp-proto-common 1.37.0\n",
            "    Uninstalling opentelemetry-exporter-otlp-proto-common-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-exporter-otlp-proto-common-1.37.0\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.37.0\n",
            "    Uninstalling opentelemetry-api-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-api-1.37.0\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.58b0\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.58b0:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.58b0\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.37.0\n",
            "    Uninstalling opentelemetry-sdk-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.37.0\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 1.2.1\n",
            "    Uninstalling langchain-core-1.2.1:\n",
            "      Successfully uninstalled langchain-core-1.2.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "opentelemetry-exporter-gcp-logging 1.11.0a0 requires opentelemetry-sdk<1.39.0,>=1.35.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\n",
            "google-adk 1.21.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.39.1 which is incompatible.\n",
            "google-adk 1.21.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed backoff-2.2.1 bcrypt-5.0.0 build-1.3.0 chromadb-1.4.0 coloredlogs-15.0.1 dataclasses-json-0.6.7 durationpy-0.10 faiss-cpu-1.13.2 groq-0.37.1 httptools-0.7.1 humanfriendly-10.0 kubernetes-34.1.0 langchain-classic-1.0.1 langchain-community-0.4.1 langchain-core-1.2.5 langchain-groq-1.1.1 langchain-text-splitters-1.1.0 langchain_openai-1.1.6 marshmallow-3.26.2 mypy-extensions-1.1.0 onnxruntime-1.23.2 opentelemetry-api-1.39.1 opentelemetry-exporter-otlp-proto-common-1.39.1 opentelemetry-exporter-otlp-proto-grpc-1.39.1 opentelemetry-proto-1.39.1 opentelemetry-sdk-1.39.1 opentelemetry-semantic-conventions-0.60b1 posthog-5.4.0 pybase64-1.4.3 pymupdf-1.26.7 pypdf-6.5.0 pypika-0.48.9 pyproject_hooks-1.2.0 requests-2.32.5 typesense-1.3.0 typing-inspect-0.9.0 urllib3-2.3.0 uvloop-0.22.1 watchfiles-1.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Document Structure\n",
        "from langchain_core.documents import Document"
      ],
      "metadata": {
        "id": "j-QI6LqG1uWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = Document(\n",
        "    page_content=\"Machine learning is fun\",\n",
        "    metadata = {                                                      # to apply filters\n",
        "        \"source\" : \"example.txt\",\n",
        "        \"page_no\" : 1,\n",
        "        \"author\" : \"firdous\",\n",
        "        \"date_created\" : \"2025-01-01\",\n",
        "    }\n",
        ")\n",
        "doc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3zpO-_Q5ou2",
        "outputId": "4d8e0a30-34a3-4458-b1b6-c3431dadf2b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'source': 'example.txt', 'page_no': 1, 'author': 'firdous', 'date_created': '2025-01-01'}, page_content='Machine learning is fun')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create simple txt file\n",
        "import os\n",
        "os.makedirs('data/text_files',exist_ok=True)"
      ],
      "metadata": {
        "id": "MroCTKT46URZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_texts={\n",
        "    \"data/text_files/python_intro.txt\":\"\"\"Python Programming Introduction\n",
        "\n",
        "Python is a high-level, interpreted programming language known for its simplicity and readability.\n",
        "Created by Guido van Rossum and first released in 1991, Python has become one of the most popular\n",
        "programming languages in the world.\n",
        "\n",
        "Key Features:\n",
        "- Easy to learn and use\n",
        "- Extensive standard library\n",
        "- Cross-platform compatibility\n",
        "- Strong community support\n",
        "\n",
        "Python is widely used in web development, data science, artificial intelligence, and automation.\"\"\",\n",
        "\n",
        "    \"data/text_files/machine_learning.txt\": \"\"\"Machine Learning Basics\n",
        "\n",
        "Machine learning is a subset of artificial intelligence that enables systems to learn and improve\n",
        "from experience without being explicitly programmed. It focuses on developing computer programs\n",
        "that can access data and use it to learn for themselves.\n",
        "\n",
        "Types of Machine Learning:\n",
        "1. Supervised Learning: Learning with labeled data\n",
        "2. Unsupervised Learning: Finding patterns in unlabeled data\n",
        "3. Reinforcement Learning: Learning through rewards and penalties\n",
        "\n",
        "Applications include image recognition, speech processing, and recommendation systems\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "}\n",
        "\n",
        "for filepath,content in sample_texts.items():\n",
        "  with open(filepath,'w',encoding=\"utf-8\") as f:\n",
        "    f.write(content)\n",
        "print(\"Sample text files created\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhAq9eBt6mZP",
        "outputId": "6b716e90-7f14-44a6-b460-7e801ddd0801"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample text files created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TextLoader\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "loader = TextLoader('data/text_files/python_intro.txt')\n",
        "document = loader.load()\n",
        "print(document)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubv_HdNqvxBd",
        "outputId": "eb875996-e29f-4762-efc4-c365dd43d0d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(metadata={'source': 'data/text_files/python_intro.txt'}, page_content='Python Programming Introduction\\n\\nPython is a high-level, interpreted programming language known for its simplicity and readability.\\nCreated by Guido van Rossum and first released in 1991, Python has become one of the most popular\\nprogramming languages in the world.\\n\\nKey Features:\\n- Easy to learn and use\\n- Extensive standard library\\n- Cross-platform compatibility\\n- Strong community support\\n\\nPython is widely used in web development, data science, artificial intelligence, and automation.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DirectoryLoader\n",
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "\n",
        "dir_loader = DirectoryLoader(\n",
        "    'data/text_files',\n",
        "    glob = \"**/*.txt\",\n",
        "    loader_cls = TextLoader,\n",
        "    loader_kwargs={'encoding' : 'utf-8'},\n",
        "    show_progress = True\n",
        ")\n",
        "\n",
        "documents = dir_loader.load()\n",
        "documents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tojSHzaZwLkc",
        "outputId": "169d9df8-d8d0-4df7-a102-14b9b232c70f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 2031.14it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'data/text_files/machine_learning.txt'}, page_content='Machine Learning Basics\\n\\nMachine learning is a subset of artificial intelligence that enables systems to learn and improve\\nfrom experience without being explicitly programmed. It focuses on developing computer programs\\nthat can access data and use it to learn for themselves.\\n\\nTypes of Machine Learning:\\n1. Supervised Learning: Learning with labeled data\\n2. Unsupervised Learning: Finding patterns in unlabeled data\\n3. Reinforcement Learning: Learning through rewards and penalties\\n\\nApplications include image recognition, speech processing, and recommendation systems\\n\\n\\n    '),\n",
              " Document(metadata={'source': 'data/text_files/python_intro.txt'}, page_content='Python Programming Introduction\\n\\nPython is a high-level, interpreted programming language known for its simplicity and readability.\\nCreated by Guido van Rossum and first released in 1991, Python has become one of the most popular\\nprogramming languages in the world.\\n\\nKey Features:\\n- Easy to learn and use\\n- Extensive standard library\\n- Cross-platform compatibility\\n- Strong community support\\n\\nPython is widely used in web development, data science, artificial intelligence, and automation.')]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "from langchain_community.document_loaders import PyMuPDFLoader,PyPDFLoader #PyMuPDF better to PyPDF\n",
        "\n",
        "dir_loader = DirectoryLoader(\n",
        "    'data/pdf_files',\n",
        "    glob = \"**/*.pdf\",\n",
        "    loader_cls = PyMuPDFLoader,\n",
        "    show_progress=True\n",
        ")\n",
        "\n",
        "documents = dir_loader.load()\n",
        "documents\n",
        "# Visit langchain documentation for other types of documents loader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYNXf9-ZxU-_",
        "outputId": "33790455-0755-4a46-9553-a75d59206b41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 1/1 [00:00<00:00,  6.70it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': 'data/pdf_files/1.ICASERT_2019_paper_690.pdf', 'file_path': 'data/pdf_files/1.ICASERT_2019_paper_690.pdf', 'total_pages': 7, 'format': 'PDF 1.6', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 0}, page_content='See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/337768246\\nBrain Tumor Detection Using Convolutional Neural Network\\nConference Paper · December 2019\\nDOI: 10.1109/ICASERT.2019.8934561\\nCITATIONS\\n338\\nREADS\\n21,110\\n5 authors, including:\\nTonmoy Hossain\\nUniversity of Virginia\\n31 PUBLICATIONS\\xa0\\xa0\\xa0702 CITATIONS\\xa0\\xa0\\xa0\\nSEE PROFILE\\nFairuz Shadmani Shishir\\nUniversity of Kansas\\n14 PUBLICATIONS\\xa0\\xa0\\xa0480 CITATIONS\\xa0\\xa0\\xa0\\nSEE PROFILE\\nMohsena Ashraf\\nAhsanullah University of Science and Technology\\n13 PUBLICATIONS\\xa0\\xa0\\xa0515 CITATIONS\\xa0\\xa0\\xa0\\nSEE PROFILE\\nMd Abdullah Al Nasim\\nPioneer Alpha\\n52 PUBLICATIONS\\xa0\\xa0\\xa0779 CITATIONS\\xa0\\xa0\\xa0\\nSEE PROFILE\\nAll content following this page was uploaded by Md Abdullah Al Nasim on 08 June 2020.\\nThe user has requested enhancement of the downloaded file.'),\n",
              " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': 'data/pdf_files/1.ICASERT_2019_paper_690.pdf', 'file_path': 'data/pdf_files/1.ICASERT_2019_paper_690.pdf', 'total_pages': 7, 'format': 'PDF 1.6', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 1}, page_content='XXX-X-XXXX-XXXX-X/XX/$XX.00 ©20XX IEEE \\n \\nBrain Tumor Detection Using Convolutional Neural \\nNetwork \\nTonmoy Hossain1*,  Fairuz Shadmani Shishir2@ , Mohsena Ashraf3# \\nMD Abdullah Al Nasim4&, Faisal Muhammad Shah5$\\nDept of CSE, Ahsanullah University of Science and Technology, Dhaka, Bangladesh \\ntonmoyhossain.cse@ieee.org*, fsshishir95@gmail.com@, mohsena.ria20@gmail.com# \\n nasim.abdullah@ieee.org&, faisal505@hotmail.com$\\nAbstract— Brain Tumor segmentation is one of the most \\ncrucial and arduous tasks in the terrain of medical image \\nprocessing as a human-assisted manual classification can result \\nin inaccurate prediction and diagnosis. Moreover, it is an \\naggravating task when there is a large amount of data present \\nto be assisted. Brain tumors have high diversity in appearance \\nand there is a similarity between tumor and normal tissues and \\nthus the extraction of tumor regions from images becomes \\nunyielding. In this paper, we proposed a method to extract brain \\ntumor from 2D Magnetic Resonance brain Images (MRI) by \\nFuzzy C-Means clustering algorithm which was followed by \\ntraditional classifiers and convolutional neural network.  The \\nexperimental study was carried on a real-time dataset with \\ndiverse tumor sizes, locations, shapes, and different image \\nintensities. In traditional classifier part, we applied six \\ntraditional classifiers namely Support Vector Machine (SVM), \\nK-Nearest Neighbor (KNN), Multilayer Perceptron (MLP), \\nLogistic Regression, Naïve Bayes and Random Forest which was \\nimplemented in scikit-learn. Afterward, we moved on to \\nConvolutional Neural Network (CNN) which is implemented \\nusing Keras and Tensorflow because it yields to a better \\nperformance than the traditional ones. In our work, CNN \\ngained an accuracy of 97.87%, which is very compelling. The \\nmain aim of this paper is to distinguish between normal and \\nabnormal pixels, based on texture based and statistical based \\nfeatures.  \\n \\nKeywords— CNN, FCM, Medical Image, segmentation, SVM  \\nI. INTRODUCTION \\nMedical imaging refers to a number of techniques that can be \\nused as non-invasive methods of looking inside the body [1]. Medical \\nimage encompasses different image modalities and processes to \\nimage the human body for treatment and diagnostic purposes and \\nhence plays a paramount and decisive role in taking actions for the \\nbetterment of the health of the people. \\nImage segmentation is a crucial and essential step in image \\nprocessing which determines the success of a higher level of image \\nprocessing [2]. The primary goal of image segmentation in medical \\nimage processing is mainly tumor or lesion detection, efficient \\nmachine vision and attaining satisfactory result for further diagnosis.  \\nImproving the sensitivity and specificity of tumor or lesion has \\nbecome a core problem in medical images with the help of Computer \\nAided Diagnostic (CAD) systems. \\n \\nAccording to [3], Brain and other nervous system cancer is the \\n10th leading cause of death, and the five-year survival rate for \\npeople with a cancerous brain is 34% for men and 36% for women. \\nMoreover, the World Health Organization (WHO) states that around \\n400,000 people in the world are affected by the brain tumor and \\n120,000 people have died in the previous years [4]. Moreover, An \\nestimated 86,970 new cases of primary malignant and non-\\nmalignant brain and other Central Nervous System (CNS) tumors \\nare expected to be diagnosed in the United States in 2019 [5]. \\n \\nA brain tumor occurs when abnormal cells form within the brain \\n[6]. There are two main types of tumors- Malignant and Benign. \\nMalignant brain tumors originate in the brain, grows faster and \\naggressively invades the surrounding tissues. It can spread to other \\nparts of the brain and affect the central nervous system. Cancerous \\ntumors can be divided into primary tumors, which start within the \\nbrain, and secondary tumors, which have spread from elsewhere, are \\nknown as brain metastasis tumors. On the other hand, a benign brain \\ntumor is a mass of cells that grow relatively slowly in the brain. \\n \\nHence, early detection of brain tumors can play an indispensable \\nrole in improving the treatment possibilities, and a higher gain of \\nsurvival possibility can be accomplished. But manual segmentation \\nof tumors or lesions is a time consuming, challenging and \\nburdensome task as a large number of MRI images are generated in \\nmedical routine. MRI, also known as Magnetic Resonance Imaging \\nis mostly used for a brain tumor or lesion detection. Brain tumor \\nsegmentation from MRI is one of the most crucial tasks in medical \\nimage processing as it generally involves a considerable amount of \\ndata. Moreover, the tumors can be ill-defined with soft tissue \\nboundaries. So it is a very extensive task to obtain the accurate \\nsegmentation of tumors from the human brain. \\n \\nIn this paper, we proposed an efficient and skillful method \\nwhich helps in the segmentation and detection of the brain tumor \\nwithout any human assistance based on both traditional classifiers \\nand Convolutional Neural Network. \\nII. LITERATURE REVIEW \\n      One of the most challenging as well as demanding task is \\nto segment the region of interest from an object and \\nsegmenting the tumor from an MRI Brain image is an \\nambitious one. Researchers around the world are working on \\nthis field to get the best-segmented ROI and various disparate \\napproaches simulated from a distinct perspective. Nowadays \\nNeural Network based segmentation gives prominent \\noutcomes, and the flow of employing this model is \\naugmenting day by day. \\n \\n      Devkota et al. [7] established the whole segmentation \\nprocess based on Mathematical Morphological Operations \\nand spatial FCM algorithm which improves the computation \\ntime, but the proposed solution has not been tested up to the \\nevaluation stage and outcomes as- Detects cancer with 92%'),\n",
              " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': 'data/pdf_files/1.ICASERT_2019_paper_690.pdf', 'file_path': 'data/pdf_files/1.ICASERT_2019_paper_690.pdf', 'total_pages': 7, 'format': 'PDF 1.6', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 2}, page_content='and classifier has an accuracy of 86.6%. Yantao et al. [8] \\nresembled \\nHistogram \\nbased \\nsegmentation \\ntechnique. \\nRegarding the brain tumor segmentation task as a three-class \\n(tumor including necrosis and tumor, edema and normal \\ntissue) classification problem regarding two modalities \\nFLAIR and T1. The abnormal regions were detected by using \\na region-based active contour model on FLAIR modality. The \\nedema and tumor tissues were distinguished in the abnormal \\nregions based on the contrast enhancement T1 modality by the \\nk-means method and accomplished a Dice coefficient and \\nsensitivity of 73.6% and 90.3% respectively. \\n \\n       Based on edge detection approaches, Badran et al. [9] \\nadopted the canny edge detection model accumulated with \\nAdaptive thresholding to extract the ROI. The dataset \\ncontained 102 images. Images were first preprocessed, then \\nfor two sets of a neural network, for the first set canny edge \\ndetection was applied, and for the second set, adaptive \\nthresholding was applied. The segmented image is then \\nrepresented by a level number and characteristics features are \\nextracted by the Harris method. Then two neural network is \\nemployed, first for the detection of healthy or tumor \\ncontaining the brain and the second one is for detecting tumor \\ntype. Depicting the outcomes and comparing these two \\nmodels, the canny edge detection method showed better \\nresults in terms of accuracy. Pei et al. [10] proposed a \\ntechnique which utilizes tumor growth patterns as novel \\nfeatures to improve texture based tumor segmentation in \\nlongitudinal MRI. Label maps are being used to obtain tumor \\ngrowth modeling and predict cell density after extracting \\ntextures (e.g., fractal, and mBm) and intensity features. \\nPerformance of the model reflected as the Mean DSC with \\ntumor cell density- LOO: 0.819302 and 3-Folder: 0.82122. \\n \\n       Dina et al. [11] introduced a model based on the \\nProbabilistic Neural Network model related to Learning \\nVector Quantization. The model was evaluated on 64 MRI \\nimages, among which 18 MRI images were used as the test \\nset, and the rest was used as a training set. The Gaussian filter \\nsmoothed the images. 79% of the processing time was reduced \\nby the modified PNN method. A Probabilistic Neural Network \\nbased segmentation technique implemented by Othman et al. \\nPrincipal Component Analysis (PCA) was used for feature \\nextraction and also to reduce the large dimensionality of the \\ndata [12]. The MRI images are converted into matrices, and \\nthen Probabilistic Neural Network is used for classification. \\nFinally, performance analysis is done. The training dataset \\ncontained 20 subjects, and the test dataset included 15 \\nsubjects. Based on the spread value, accuracy ranged from \\n73% to 100%. \\n \\n        Concentrating on Region based Fuzzy Clustering and \\ndeformable model, Rajendran et al. [13] accomplished 95.3% \\nand 82.1% of ASM and Jaccard Index based on Enhanced \\nProbabilistic Fuzzy C-Means model with some morphological \\noperations. Zahra et al. [14] performed with LinkNet network \\nfor tumor segmentation. Initially, they used a single Linknet \\nnetwork and sent all training seven datasets to that network for \\nsegmentation. They did not consider the view angle of the \\nimages and introduced a method for CNN to automatically \\nsegment the most common types of a brain tumor which do \\nnot require preprocessing steps. Dice score of 0.73 is achieved \\nfor a single network, and 0.79 is obtained for multiple systems. \\nIII. PROPOSED METHODOLOGY \\nIn our proposed methodology, there are two distinct model \\nfor segmentation and detection of Brain tumor. First model \\nsegmented the tumor by FCM and classified by traditional \\nmachine learning algorithms and the second model focused on \\ndeep learning for tumor detection. Segmentation by FCM \\ngives better result for noisy clustered data set [15]. Though it \\ntakes more execution time, it retains more information.  \\nA. Proposed Methodology of Tumor Segmentation and \\nClassification Using Traditional Classifiers \\nIn our first prospective model, brain tumor segmentation \\nand detection using machine learning algorithm had been \\ndone, and a comparison of the classifiers for our model is \\ndelineated. Our proposed Brain image segmentation system \\nconsists of seven stages: skull stripping, filtering and \\nenhancement, segmentation by Fuzzy C Means algorithm, \\nmorphological \\noperations, \\ntumor \\ncontouring, \\nfeature \\nextraction and classification by traditional classifiers. The \\nresults of our work accomplished satisfactory results. The \\nmain stages of our proposed model (Fig. 1) will be illustrated \\nin the following sections. \\n \\n \\nFig. 1. Proposed methodology for classification using Traditional \\nClassifiers \\n1) Skull Stripping: Skull stripping is a very important step \\nin medical image processing because of the background of \\nthe MRI image not containing any useful information, and it \\nonly increases the processing time. In our work, we removed \\nthe skull portion from the MRI images in three steps. These \\nthree steps are: \\n \\na) Otsu Thresholding: For skull removal, at first we \\nused Otsu’s Thresholding method which automatically \\ncalculates the threshold value and segments the image into \\nbackground and foreground. In this method, the threshold that \\nis selected minimizes the intra-class variance, defined as a \\nweighted sum of deviations of the two classes. \\n \\nb) Connected Component Analysis: At the last stage of \\nour skull stripping step, we used connected component \\nanalysis to extract only the brain region and as a consequence \\nthe skull part was removed. \\n \\n2) Filtering and Enhancement: For better segmentation, \\nwe need to maximize the MRI image quality with minimized \\nnoise as brain MRI images are more sensitive to noise than \\nany other medical image. Gaussian blur filter was used in our'),\n",
              " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': 'data/pdf_files/1.ICASERT_2019_paper_690.pdf', 'file_path': 'data/pdf_files/1.ICASERT_2019_paper_690.pdf', 'total_pages': 7, 'format': 'PDF 1.6', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 3}, page_content='work for Gaussian noise reduction existing in Brain MRI \\nwhich prevailed the performance of the segmentation. \\n \\n3) Segmentation using FCM: Fuzzy C-Means clustering \\nalgorithm was used for segmentation, which allows one piece \\nof data to belong to two or more clusters. We got the fuzzy \\nclustered segmented image at this stage, which ensured a \\nbetter segmentation.  \\n \\n4) Morphological Operation: To segment the tumor, we \\nonly need the brain part rather than the skull part. For this, we \\napplied morphological operations in our images. At first, \\nerosion was done to separate weakly connected regions of the \\nMRI image. After erosion, we will get multiple disconnected \\nregions in our images. Dilation was applied afterwards.  \\n \\n5) Tumor Contouring: Tumor cluster extraction was done \\nby an intensity based approach which is thresholding. The \\noutput of this image is the highlighted tumor area with a dark \\nbackground. \\n \\n6) Feature Extaction: Two types of features were \\nextracted for classification. Texture-based features such as- \\nDissimilarity, Homogeneity, Energy, Correlation, ASM and \\nStatistical based features including- Mean, Entropy, \\nCentroid, Standard Deviation, Skewness, Kurtosis were \\nextracted from the segmented MRI Images. \\n \\n7) Traditional Classifiers: We used six traditional \\nmachine learning classifiers which are K-Nearest Neighbor, \\nLogistic Regression, Multilayer Perceptron, Naïve Bayes, \\nRandom Forest, and Support Vector Machine to get the \\naccuracy of tumor detection of our proposed model. \\n \\n8) Evaluation Stage: Implementing other region-based \\nsegmentation methods and comparing it to our proposed \\nsegmentation technique, our model segments the ROI and \\nsegregates the tumor portion most accurately. An illustration \\nof the whole process is depicted in Fig. 5. After segmentation \\nand feature extraction from the tumor, we applied six \\nclassification techniques.  Among them, we got the best result \\nfrom SVM and obtained an accuracy of 92.42%. \\n \\nB. Proposed Methodology Using CNN \\nConvolutional Neural Network is broadly used in the field \\nof Medical image processing. Over the years lots of \\nresearchers tried to build a model which can detect the tumor \\nmore efficiently. We tried to come up with an exemplary \\nwhich can accurately classify the tumor from 2D Brain MRI \\nimages. A fully-connected neural network can detect the \\ntumor, but because of parameter sharing and sparsity of \\nconnection, we adopted CNN for our model. \\n \\n A Five-Layer Convolutional Neural Network is \\nintroduced and implemented for tumor detection. The \\naggregated model consisting of seven stages including the \\nhidden layers provides us with the most prominent result for \\nthe apprehension of the tumor. Following is the proposed \\nmethodology with a brief narration-   \\n \\nFig. 2. Proposed Methodology for tumor detection using 5-Layer \\nConvolutional Neural Network \\nUsing convolutional layer as the beginner layer, an input \\nshape of the MRI images is generated which is 64*64*3 \\nconverting all the images into a homogeneous dimension. \\nAfter accumulating all the images in the same aspect, we \\ncreated a convolutional kernel that is convoluted with the \\ninput layer — administering with 32 convolutional filters of \\nsize 3*3 each with the support of 3 channels tensors. ReLU \\nis used as an activation function so that it’s not corroborating \\nwith the output. \\n \\nIn this ConvNet architecture, progressively shorten the \\nspatial size of the depiction for diminishing the chunk of \\nparameters and computational time of the network. Working \\non the Brain MRI image can also cost the contamination of \\nthe overfitting and for this Max Pooling layer perfectly works \\nfor this perception. For spatial data which substantiate with \\nour input image, we use MaxPooling2D for the model. This \\nconvolutional layer runs on 31*31*32 dimension. Because of \\ndivide the input images in both spatial dimensions, the pool \\nsize is (2, 2) which means a tuple of two integers by which to \\ndownscale by vertically and horizontally. \\n \\nAfter the pooling layer, a pooled feature map is obtained. \\nFlattening is one of the essential layers after the pooling \\nbecause we’ve to transformed the whole matrix representing \\nthe input images into a single column vector and it’s \\nimperative for processing. It is then fed to the Neural \\nNetwork for the processing. \\n \\nTwo fully connected layers were employed Dense-1 and \\nDense-2 represented the dense layer. The dense function is \\napplied in Keras for the processing of the Neural Network, \\nand the obtained vector is work as an input for this layer. \\nThere are 128 nodes in the hidden layer. Because the number \\nof dimension or nodes proportional with the computing \\nresources we need to fit our model we kept it as moderate as \\npossible and for this perspective 128 nodes gives the most \\nsubstantial result. ReLU is used as the activation function \\nbecause of showing better convergence performance. After \\nthe first dense layer, the second fully connected layer was \\nused as the final layer of the model. In this layer, we used \\nsigmoid function as activation function where the total \\nnumber of the node is one because we need to lower the uses \\nof computing resources so that a more significant amount \\nassuages the execution time. Though there is a chance of'),\n",
              " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': 'data/pdf_files/1.ICASERT_2019_paper_690.pdf', 'file_path': 'data/pdf_files/1.ICASERT_2019_paper_690.pdf', 'total_pages': 7, 'format': 'PDF 1.6', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 4}, page_content='hampering the learning in deep networks for using of the \\nsigmoid as the activation function, we scale the sigmoid \\nfunction, and the number of the nodes is much lesser and easy \\nto handle for this deep network. In a summary, Fig. 3 shown \\nthe working flow of the proposed CNN model. \\n \\n \\nFig. 3. Working flow of the proposed CNN Model. \\nUsing Adam optimizer and binary cross-entropy as a loss \\nfunction, we compiled the model and find the accuracy of \\ndetecting the tumor. An algorithm is depicted in Fig. 4 where \\nwe evaluated the performance of the model. \\n \\n \\nFig. 4. Algorithm of the performance evaluation \\nAll the hyper-parameters value are constituted in Table-I. \\nApproximately 97.87% is achieved as the accuracy. \\nTABLE I.  \\nHYPERPARAMETER VALUE OF CNN MODEL  \\nStage \\nHyper-parameter \\nValue \\nInitialization \\nbias  \\nZeros \\nWeights \\nglorot_uniform \\n \\n \\n \\n \\nTraining \\nLearning rate \\n0.001 \\nbeta_1 \\n0.9 \\nbeta_2 \\n0.999 \\nepsilon \\nNone \\ndecay \\n0.0 \\namsgrad \\nFalse \\nepoch \\n10 \\nStage \\nHyper-parameter \\nValue \\nBatch_size \\n32 \\nsteps_per_epoch \\n80 \\n \\nIV. EXPERIMENTAL RESULTS \\nTo justify our proposed model, steps of segmenting the \\ntumor from 2D Brain MRI is illustrated (Fig. 5) and a \\ncomparative analysis of our proposed models of classification \\nusing machine learning, and deep learning is shown. We got \\n92.42% of accuracy using SVM and 97.87% of accuracy is \\nachieved using CNN.  \\nA. Experimental Dataset \\nFor Performance Evaluation of our proposed model, we \\nused the benchmark dataset in the field of Brain Tumor \\nSegmentation, and that is BRATS dataset [16], consisting \\ntwo classes’— class-0 and class-1 represents the Non-Tumor \\nand Tumor MRI images. 187 and 30 MRI Images containing \\ntumor and non-tumor respectively classified as class-1 and \\nclass-0. All the images are MRI images from different \\nmodalities like- T1, T2, and FLAIR. For traditional machine \\nlearning classifiers, we obtained the superlative result \\nsplitting the dataset by 70 to 30 in terms of training to testing \\nimages, and for CNN, we divided the dataset in both 70 to 30 \\nand 80 to 20 formation and compared the outcomes. \\nB. Segmentation using Image processing techniques \\nBased on our proposed methodology, we segmented the \\ntumor without loss of any subtle information. We removed the \\nskull because for tumor segmentation the role of skull is \\napproximately null and ambiguous in this process.  \\n  \\n \\n \\n(a) Input Image                (b) Skull Stripping         (c) Gaussian Filtering \\n \\n \\n \\n \\n   (d) Image Enhancement       (e) Segmentation           (f) Tumor Contouring \\nFig. 5. Segmentation processes of an MRI \\n \\nFrom the dataset, a 2D MRI was taken as an input image, \\nSkull stripping technique is performed on the input image \\n(Fig. 1b) followed by image enhancement (Fig. 1c) for \\nunderstanding the features of the MRI properly. After that, \\nGaussian filter (Fig. 1d) is used for noise removal and finally \\nsimulating the FCM segmentation technique (Fig. 1e) \\nfollowed by tumor contouring (Fig. 1f) to find out the ROI \\nwhich is the tumor for Brain MRI. After the segmentation of \\nthe tumor, we classified the tumor based on different \\ntraditional Machine learning Algorithms.'),\n",
              " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': 'data/pdf_files/1.ICASERT_2019_paper_690.pdf', 'file_path': 'data/pdf_files/1.ICASERT_2019_paper_690.pdf', 'total_pages': 7, 'format': 'PDF 1.6', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 5}, page_content='C. Classification Using Machine Learning \\nTexture and Statistical based features are more popular \\nfor detecting the Region of Interest (ROI). Based on these \\nfeatures we can segregate the tumorous and non-tumorous \\nMRI. We used texture and statistical based features for \\nclassification. Texture-based features like- Dissimilarity, \\nHomogeneity, Energy, Correlation, ASM and Statistical \\nbased features including- Mean, Entropy, Centroid, Standard \\nDeviation, Skewness, Kurtosis were extracted from the \\nsegmented Brain tumor. Further, we extracted the Area, \\nConvex Hull Area and Diameter of the tumor. Extrapolating \\nthese features from the segmented MRI, we classified the \\nimage as the existence of normal and abnormal tissue. Table-\\nII depicts the values of the features of some of the segmented \\nMRI.  After feature extraction, classification had been done. \\nWe adopt six classifiers which are- KNN, Logistic \\nRegression, Multilayer Perception, Naïve Bayes, Random \\nForest, and SVM and achieved the best accuracy as the \\nperformance from SVM. Confusion Metrics’ along with the \\nperformance of the classifiers is characterized in Table-III. \\nThe following factor evaluates the performance- \\n \\n𝐴𝑐𝑐𝑢𝑟𝑎𝑐𝑦= \\n𝑇𝑃+𝑇𝑁\\n𝑇𝑃+𝐹𝑃+𝑇𝑁+𝐹𝑁                                               (1)      \\n𝑆𝑒𝑛𝑠𝑖𝑡𝑖𝑣𝑖𝑡𝑦(𝑟𝑒𝑐𝑎𝑙𝑙) = \\n𝑇𝑃\\n𝑇𝑃+𝐹𝑁                                          (2) \\n𝑆𝑝𝑒𝑓𝑖𝑐𝑖𝑡𝑦= \\n𝑇𝑁\\n𝑇𝑁+𝐹𝑃                                                           (3) \\n𝑃𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛 (𝑃𝑃𝑉) = \\n𝑇𝑃\\n𝑇𝑃+𝐹𝑃                                               (4) \\nTABLE II.  \\nEXTRACTED  FEATURES FROM SEGMENTED TUMOR \\nImage \\nNo \\nContrast \\nDissimilarity \\nHomogeneity \\nEnergy \\nCorrelation \\nASM \\nLabel \\n1 \\n281.18 \\n1.37 \\n0.97 \\n0.90 \\n0.97 \\n0.81 \\n1 \\n2 \\n97.36 \\n0.53 \\n0.98 \\n0.98 \\n0.94 \\n0.96 \\n1 \\n3 \\n337.39 \\n1.68 \\n0.98 \\n0.97 \\n0.82 \\n0.95 \\n1 \\n4 \\n357.59 \\n2.34 \\n0.94 \\n0.92 \\n0.90 \\n0.86 \\n1 \\n5 \\n149.37 \\n0.82 \\n0.98 \\n0.96 \\n0.96 \\n0.93 \\n0 \\n6 \\n357.59 \\n2.34 \\n0.95 \\n0.93 \\n0.90 \\n0.86 \\n0 \\nTABLE III.  \\nCONFUSION METRICS’ OF THE CLASSIFIERS \\nClassifiers \\nAccuracy \\nRecall \\nSpecificity \\nPrecision \\nDice Score \\nJaccard Index \\nK-Nearest Neighnout \\n89.39 \\n0.949 \\n0.428 \\n0.933 \\n0. 941 \\n0.889 \\nLogistic Regression \\n87.88 \\n0.949 \\n0.286 \\n0.918 \\n0.933 \\n0.875 \\nMultilayer Perception \\n89.39 \\n1.000 \\n0 \\n0.894 \\n0.944 \\n0.894 \\nNaïve Bayes \\n78.79 \\n0.797 \\n0.714 \\n0.959 \\n0.870 \\n0.770 \\nRandom Forest \\n89.39 \\n0.983 \\n0.167 \\n0.903 \\n0.943 \\n0.892 \\nSVM \\n92.42 \\n0.983 \\n0.428 \\n0.935 \\n0.959 \\n0.921 \\n      From Table-III, we characterized that, among the six \\ntraditional machine learning classifiers, SVM gives the most \\nprominent result and it is 92.42% in terms of accuracy. \\nThough in terms of Precision and Specificity, Naïve Bayes \\ngave the prominent outcome but the discrepancy with SVM \\nwas very subtle and also negligible considering the other \\nperformance metrics. From other performance metrics’, it’s \\nalso concluded that from SVM we obtained the pre-eminent \\nresult in terms of Jaccard Index, Dice Score, Precision, recall \\netc.  \\nD. Classification Using CNN \\nThe five-layer proposed methodology gives us the \\ncommendable result for the detection of the tumor. \\nConvolution, Max Pooling, Flatten, and two dense layers are \\nthe proposed five layer CNN model. Data augmentation had \\nbeen done before fitting the model as CNN is translation \\ninvariance. We evaluate the performance in two ways based \\non splitting the dataset. We accomplish 92.98% of accuracy \\nfor 70:30 splitting ratio where the training accuracy is \\n99.01%. Then at the second iteration, 80% of the images \\nassigned for training and the rest of the images accredited for \\ntesting where we concluded 97.87% of accuracy and 98.47% \\nof training accuracy. So our proposed model gives the best \\nresult when the division is 80:20. Table-IV represents the \\nperformance of the proposed methodology based on CNN. \\n \\nWe got 97.87% as accuracy which is remarkable in terms \\nof using five-layer CNN. We analyzed with a different \\nnumber of layers but the divergent of the outcomes were not \\nvery significant in terms of using this five-layer CNN model. \\nSome of the aspects that we obtained when we increase the \\nnumber of layers is- computation time, the complexity of the \\nmethod batch size and steps per was immensely high. Further, \\nwe used 0.2 as the dropout value but did not commensurate \\nthe model as the accuracy flattened. As a result, this model \\nprovides the best accuracy without using dropout. \\nTABLE IV.  \\nPERFORMANCE OF THE PROPOSED CNN MODEL \\nNo \\nTraining \\nImage \\nTesting \\nImage \\nSplitting \\nRatio \\nAccuracy \\n(%) \\n1 \\n152 \\n65 \\n70 : 30 \\n92.98 \\n2 \\n174 \\n43 \\n80 : 20 \\n97.87 \\n \\n     Fig. 6 depicts the training and validation accuracy of our \\nmodel. It was calculated by the keras callbacks function. \\nOperating with the different number of epochs we observed'),\n",
              " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': 'data/pdf_files/1.ICASERT_2019_paper_690.pdf', 'file_path': 'data/pdf_files/1.ICASERT_2019_paper_690.pdf', 'total_pages': 7, 'format': 'PDF 1.6', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 6}, page_content='the training and validation accuracy. We found that after 9 \\nepochs model has the maximum accuracy for both training \\nand validation. \\n \\nFig. 6. Accuracy of the proposed CNN model. \\nE. Performance Comparison  \\nFinally, we carried out a comparison between our \\nproposed methodologies which are classification using \\ntraditional machine learning classifiers and CNN. We also \\ncompared our result with some other research articles which \\nworked on the same dataset. In Seetha et al. [17], researchers \\ngot 83.0% accuracy using SVM based classification and \\n97.5% accuracy using CNN. Our proposed methodology \\nprovided an improved result for both machine learning and \\nCNN based classification. Mariam et al. [18] got \\napproximately 95% of dice co-efficient where we have 96% \\nas the Dice score. \\nTABLE V.  \\nPERFORMANCE COMPARISON \\nMethodology \\nAccuracy (%) \\nSeetha et al [17] \\n97.5 \\nProposed CNN Model \\n97.87 \\n \\nCONCLUSION AND FUTURE WORK \\n      Image segmentation plays a significant role in medical \\nimage processing as medical images have different \\ndiversities. For brain tumor segmentation, we used MRI and \\nCT scan images. MRI is most vastly used for brain tumor \\nsegmentation and classification. In our work, we used Fuzzy \\nC-Means clustering for tumor segmentation which can \\npredict tumor cells accurately. The segmentation process was \\nfollowed by classification using traditional classifiers and \\nConvolutional Neural Network. In the traditional classifier \\npart, we applied and compared the results of different \\ntraditional classifiers such as K-Nearest Neighbor, Logistic \\nRegression, Multilayer Perceptron, Naïve Bayes, Random \\nForest, and Support Vector Machine. Among these traditional \\nones, SVM gave us the highest accuracy of 92.42%. \\n \\n      Further, for better results, we implemented CNN which \\nbrought in the accuracy 97.87% with a split ratio of 80:20 of \\n217 images, i.e. 80% of training images and 20% of testing \\nimages. In the future, we plan to work with 3D brain images, \\nachieve more efficient brain tumor segmentation. Working \\nwith a larger dataset will be more challenging in this aspect, \\nand we want to build a dataset emphasizing the abstract with \\nrespect to our country which will accelerate the scope of our \\nwork. \\nREFERENCES \\n[1] Kasban, Hany & El-bendary, Mohsen & Salama, Dina. (2015). “A \\nComparative Study of Medical Imaging Techniques”. International \\nJournal of Information Science and Intelligent System. 4. 37-58.J. \\nClerk Maxwell, A Treatise on Electricity and Magnetism, 3rd ed., vol. \\n2. Oxford: Clarendon, 1892, pp.68–73. \\n[2] D. Surya Prabha and J. Satheesh Kumar, “Performance Evaluation of \\nImage Segmentation using Objective Methods”, Indian Journal of \\nScience and Technology, Vol 9(8), February 2016. \\n[3] Brain Tumor: Statistics, Cancer.Net Editorial Board, 11/2017 \\n(Accessed on 17th January 2019) \\n[4] Kavitha Angamuthu Rajasekaran and Chellamuthu Chinna Gounder, \\nAdvanced Brain Tumour Segmentation from MRI Images, 2018. \\n[5] General Information About Adult Brain Tumors\". NCI. 14 April \\n2014. Archived from the original on 5 July 2014. Retrieved 8 \\nJune 2014. (Accessed on 11th January 2019) \\n[6] M. Young, The Technical Writer’s Handbook. Mill Valley, CA: \\nUniversity Science, 1989. \\n[7] B. Devkota, Abeer Alsadoon, P.W.C. Prasad, A. K. Singh, A. \\nElchouemi, “Image Segmentation for Early Stage Brain Tumor \\nDetection using Mathematical Morphological Reconstruction,” 6th \\nInternational Conference on Smart Computing and Communications, \\nICSCC 2017, 7-8 December 2017, Kurukshetra, India. \\n[8] Song, Yantao & Ji, Zexuan & Sun, Quansen & Yuhui, Zheng. (2016). \\n“A Novel Brain Tumor Segmentation from Multi-Modality MRI via A \\nLevel-Set-Based Model”. Journal of Signal Processing Systems. 87. \\n10.1007/s11265-016-1188-4. \\n[9] Ehab F. Badran, Esraa Galal Mahmoud, Nadder Hamdy, “An \\nAlgorithm for Detecting Brain Tumors in MRI Images”, 7th \\nInternational Conference on Cloud Computing, Data Science & \\nEngineering - Confluence, 2017. \\n[10] Pei L, Reza SMS, Li W, Davatzikos C, Iftekharuddin KM. “Improved \\nbrain tumor segmentation by utilizing tumor growth model in \\nlongitudinal brain MRI”. Proc SPIE Int Soc Opt Eng. 2017. \\n[11] Dina Aboul Dahab, Samy S. A. Ghoniemy, Gamal M. Selim, \\n“Automated Brain Tumor Detection and Identification using Image \\nProcessing and Probabilistic Neural Network Techniques”, IJIPVC, \\nVol. 1, No. 2, pp. 1-8, 2012. \\n[12] Mohd Fauzi Othman, Mohd Ariffanan and Mohd Basri, “Probabilistic \\nNeural Network for Brain Tumor Classification”, 2nd International \\nConference on Intelligent Systems, Modelling and Simulation, 2011. \\n[13] A. Rajendran, R. Dhanasekaran, “Fuzzy Clustering and Deformable \\nModel for Tumor Segmentation on MRI Brain Image: A Combined \\nApproach,” International Conference on Communication Technology \\nand System Design 2011. \\n[14] Sobhaninia, Zahra & Rezaei, Safiyeh & Noroozi, Alireza & Ahmadi, \\nMehdi & Zarrabi, Hamidreza & Karimi, Nader & Emami, Ali & \\nSamavi, Shadrokh. (2018). “Brain Tumor Segmentation Using Deep \\nLearning by Type Specific Sorting of Images”. \\n[15] Gupta, Gaurav and Vinay Singh. “Brain Tumor segmentation and \\nclassification using Fcm and support vector machine.” (2017). \\n[16] Anam Mustaqeem, Ali Javed, Tehseen Fatima, “An Efficient Brain \\nTumor Detection Algorithm Using Watershed & Thresholding Based \\nSegmentation”, I.J. Image, Graphics and Signal Processing, 2012, 10, \\n34-39. \\n[17] Seetha, J & Selvakumar Raja, S. (2018). “Brain Tumor Classification \\nUsing Convolutional Neural Networks. Biomedical and Pharmacology \\nJournal”. 11. 1457-1461. 10.13005/bpj/1511. \\n[18] Mariam Saii, Zaid Kraitem, “Automatic Brain tumor detection in MRI \\nusing image processing techniques”, Biomedical Statistics and \\nInformatics, Vol. 2, No. 2, pp. 73-76, 2017. \\n \\n \\n \\n \\n \\n \\nView publication stats')]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RAG Pipeline : Data Ingestion to vector DB pipeline"
      ],
      "metadata": {
        "id": "NL7DE2lt4V7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_community.document_loaders import  PyMuPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "uIbTTWt67vg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read all the pdfs inside directory\n",
        "def process_all_pdfs(pdf_directory):\n",
        "  \"\"\"Process all pdfs in a directory\"\"\"\n",
        "\n",
        "  all_documents = []\n",
        "  pdf_dir = Path(pdf_directory)\n",
        "\n",
        "  pdf_files = list(pdf_dir.glob(\"**/*.pdf\"))\n",
        "  print(f\"Found {len(pdf_files)} PDF files to process\")\n",
        "\n",
        "  for pdf_file in pdf_files:\n",
        "    print(f'\\nProcessing : {pdf_file.name}')\n",
        "    try:\n",
        "      loader = PyMuPDFLoader(str(pdf_file))\n",
        "      documents = loader.load()\n",
        "\n",
        "      for doc in documents:\n",
        "        doc.metadata['source_file'] = pdf_file.name\n",
        "        doc.metadata['file_type'] = 'pdf'\n",
        "\n",
        "      all_documents.extend(documents)\n",
        "      print(f\"Loaded {len(documents)} pages\")\n",
        "    except Exception as e:\n",
        "      print(f\"Error : {e}\")\n",
        "\n",
        "  print(f\"Total documents loaded: {len(all_documents)}\")\n",
        "  return all_documents\n"
      ],
      "metadata": {
        "id": "ZntWQIus-TRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_pdf_documents = process_all_pdfs('data/pdf_files')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQ0FrQil_fRh",
        "outputId": "f4ee712a-7c7d-4622-b51f-bcee4a4d1193"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3 PDF files to process\n",
            "\n",
            "Processing : Firdous Shaikh.pdf\n",
            "Loaded 1 pages\n",
            "\n",
            "Processing : Placement brochure.pdf\n",
            "Loaded 24 pages\n",
            "\n",
            "Processing : 1.ICASERT_2019_paper_690.pdf\n",
            "Loaded 7 pages\n",
            "Total documents loaded: 32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Text Splitting get into chuncks\n",
        "def split_documents()"
      ],
      "metadata": {
        "id": "NLbWRF6oJRUE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}