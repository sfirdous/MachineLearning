test$X2,
test$X3,
radius = 0.3,
col=test$Y_hat
)
open3d()
plot3d(train$X1,
train$X2,
train$X3,
type = "s",
radius = 0.3,
col=train$Y,
xlab = "X1",
ylab = "X2",
zlab = "X3",
add = FALSE)
plot3d(test$X1,
test$X2,
test$X3,
radius = 0.3,
col=test$Y_hat
)
# Plot the training data
plot3d(train$X1, train$X2, train$X3,
type = "s", radius = 0.3,
col = train$Y, xlab = "X1",
ylab = "X2", zlab = "X3")
# Add test data to the same plot
points3d(test$X1, test$X2, test$X3,
col = "black", size = 10)
# Add test data to the same plot
points3d(test$X1, test$X2, test$X3,
col = "black", size = 10)
# Plot the training data
plot3d(train$X1, train$X2, train$X3,
type = "s", radius = 0.3,
col = train$Y, xlab = "X1",
ylab = "X2", zlab = "X3")
# Add test data to the same plot
points3d(test$X1, test$X2, test$X3,
col = "black", size = 10,add = TRUE)
# Add test data to the same plot
points3d(test$X1, test$X2, test$X3,
col = "pink", size = 10,add = TRUE)
# Add test data to the same plot
points3d(test$X1, test$X2, test$X3,
col = "pink", size = 10)
# Add test data to the same plot
points3d(test$X1, test$X2, test$X3,
col = "pink", size = 10)
test
colnames(test) = c("X1","X2","X3")
# Plot the training data
plot3d(train$X1, train$X2, train$X3,
type = "s", radius = 0.3,
col = train$Y, xlab = "X1",
ylab = "X2", zlab = "X3")
# Add test data to the same plot
points3d(test$X1, test$X2, test$X3,
col = "pink", size = 10)
# Plot the training data
plot3d(train$X1, train$X2, train$X3,
type = "s", radius = 0.3,
col = train$Y, xlab = "X1",
ylab = "X2", zlab = "X3")
# Add test data to the same plot
points3d(test$X1, test$X2, test$X3,
col = test$Y_hat, radius = 0.3)
# Add test data to the same plot
points3d(test$X1, test$X2, test$X3,
col = test$Y_hat, radius = 0.3)
# Add test data to the same plot
points3d(test$X1, test$X2, test$X3,
col = test$Y_hat, type = "s",radius = 0.3)
# Plot the training data
plot3d(train$X1, train$X2, train$X3,
type = "s", radius = 0.3,
col = train$Y, xlab = "X1",
ylab = "X2", zlab = "X3")
# Add test data to the same plot
points3d(test$X1, test$X2, test$X3,
col = test$Y_hat, type = "s",radius = 0.3)
# Add test data to the same plot
points3d(test$X1, test$X2, test$X3,
col = test$Y_hat, type = "p",radius = 0.3)
# Plot training data (spheres for clarity)
plot3d(train$X1, train$X2, train$X3,
col = train$Y, size = 10, # `size` controls point size
xlab = "X1", ylab = "X2", zlab = "X3")
# Add test data (different shape for differentiation)
points3d(test$X1, test$X2, test$X3,
col = test$Y_hat, size = 12, pch = 19)  # `pch = 19` makes solid circles
library(rgl)
# Plot training data (spheres for clarity)
plot3d(train$X1, train$X2, train$X3,
col = train$Y, size = 10, # `size` controls point size
xlab = "X1", ylab = "X2", zlab = "X3")
# Add test data (different shape for differentiation)
points3d(test$X1, test$X2, test$X3,
col = test$Y_hat, size = 12, pch = 19,add = TRUE)  # `pch = 19` makes solid circles
# Add test data (different shape for differentiation)
points3d(test$X1, test$X2, test$X3,
col = test$Y_hat, size = 12, pch = 19,add = TRUE)  # `pch = 19` makes solid circles
colnames(test) = c("X1","X2","X3","Y_hat")
plot3d(test$X1,
test$X2,
test$X3,
type = "s",
radius = 0.25,
col=test$Y_hat,
xlab = "X1",
ylab = "X2",
zlab = "X3")
plot3d(test$X1,
test$X2,
test$X3,
type = "s",
radius = 0.25,
col=test$Y_hat,
xlab = "X1",
ylab = "X2",
zlab = "X3",add = TRUE)
plot3d(train$X1,
train$X2,
train$X3,
type = "s",
radius = 0.25,
col=train$Y,
xlab = "X1",
ylab = "X2",
zlab = "X3")
plot3d(test$X1,
test$X2,
test$X3,
type = "s",
radius = 0.25,
col=test$Y_hat,
xlab = "X1",
ylab = "X2",
zlab = "X3",add = TRUE)
plot3d(train$X1,
train$X2,
train$X3,
type = "s",
radius = 0.25,
col=train$Y,
xlab = "X1",
ylab = "X2",
zlab = "X3")
plot3d(test$X1,
test$X2,
test$X3,
type = "s",
radius = 0.25,
col=test$Y_hat,
xlab = "X1",
ylab = "X2",
zlab = "X3",add = TRUE,alpha = 0.9)
plot3d(test$X1,
test$X2,
test$X3,
type = "p",
radius = 0.25,
col=test$Y_hat,
xlab = "X1",
ylab = "X2",
zlab = "X3",add = TRUE,alpha = 0.9)
plot3d(train$X1,
train$X2,
train$X3,
type = "s",
radius = 0.25,
col=train$Y,
xlab = "X1",
ylab = "X2",
zlab = "X3")
plot3d(test$X1,
test$X2,
test$X3,
type = "p",
radius = 0.25,
col=test$Y_hat,
xlab = "X1",
ylab = "X2",
zlab = "X3",add = TRUE,alpha = 0.9)
for (i in 1:nrow(test)) {
wire3d(translate3d(sphere3d(radius = 0.25),
test$X1[i], test$X2[i], test$X3[i]),
col = "black", lwd = 2)  # `lwd` controls border thickness
}
plot3d(test$X1,
test$X2,
test$X3,
col=test$Y_hat,
size = 12, pch = 19,add = TRUE)
plot3d(train$X1,
train$X2,
train$X3,
type = "s",
radius = 0.25,
col=train$Y,
xlab = "X1",
ylab = "X2",
zlab = "X3")
plot3d(test$X1,
test$X2,
test$X3,
col=test$Y_hat,
size = 12, pch = 19,add = TRUE)
plot3d(train$X1,
train$X2,
train$X3,
type = "s",
radius = 0.15,
col=train$Y,
xlab = "X1",
ylab = "X2",
zlab = "X3")
plot3d(test$X1,
test$X2,
test$X3,
col=test$Y_hat,
size = 12, pch = 19,add = TRUE)
plot3d(test$X1,
test$X2,
test$X3,
col=test$Y_hat,
size = 10, pch = 19,add = TRUE)
plot3d(train$X1,
train$X2,
train$X3,
type = "s",
radius = 0.15,
col=train$Y,
xlab = "X1",
ylab = "X2",
zlab = "X3")
plot3d(test$X1,
test$X2,
test$X3,
col=test$Y_hat,
size = 10, pch = 19,add = TRUE)
title3d(main = paste("Visualization of Training Data and Test Data for K =", 3))
library(rgl)
plot3d(train$X1,
train$X2,
train$X3,
type = "s",
radius = 0.15,
col=train$Y,
xlab = "X1",
ylab = "X2",
zlab = "X3")
plot3d(test$X1,
test$X2,
test$X3,
col=test$Y_hat,
size = 10, pch = 19,add = TRUE)
plot3d(test$X1,
test$X2,
test$X3,
col=test$Y_hat,
title3d(main = paste("Visualization of Training Data and Test Data for K =", 3))
size = 10, pch = 19,add = TRUE)
title3d(main = paste("Visualization of Training Data and Test Data for K =", 3))
rglwidget()
plot3d(train$X1,
train$X2,
train$X3,
type = "s",
radius = 0.15,
col=train$Y,
xlab = "X1",
ylab = "X2",
zlab = "X3")
plot3d(test$X1,
test$X2,
test$X3,
col=test$Y_hat,
size = 10, pch = 19,add = TRUE)
title3d(main = paste("Visualization of Training Data and Test Data for K =", 3))
rglwidget()
library(rgl)
plot3d(train$X1,
train$X2,
train$X3,
type = "s",
radius = 0.15,
col=train$Y,
xlab = "X1",
ylab = "X2",
zlab = "X3")
plot3d(test$X1,
test$X2,
test$X3,
col=test$Y_hat,
size = 10, pch = 19,add = TRUE)
title3d(main = paste("Visualization of Training Data and Test Data for K =", 3))
rglwidget()
View(train)
install.packages("ggplot2")
install.packages("ggplot2")
?aes
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("reshape")
#Load required libraries
library(ggplot2)
library(reshape)
carmat = cor(data[1:8])
class(data)
carmat = cor(as.data.frame(data[1:8]))
carmat = cor(as.data.frame(data[1:8]))
predictors = as.data.frame(data[1:8])
carmat = cor(dataset[1:8])
#store dataset
dataset = read.csv("Concrete_Data.csv")
carmat = cor(dataset[1:8])
cormat = cor(dataset[1:8])
cormat
#store dataset
dataset = read.csv("Concrete_Data.csv")
#rename columns of dataset for simplicity
colnames(dataset) = c("Cement","Blast Furnace Slag"," Fly Ash","Water ","Superplasticizer","Coarse Aggregate","Fine Aggregate"," Age (day)","CCS")
#store the dimensions of dataset
n = nrow(dataset)                         #number of instances
p = ncol(dataset) - 1                     #number of predictors
summary(dataset)
par(mfrow = c(2, 4))
for (i in 1:p) {
hist(dataset[,i],'FD',col = "lightblue",main = paste(colnames(dataset)[i]),xlab = colnames(dataset)[i])
abline(v = mean(dataset[,i]) , lty = 2)
}
boxplot(dataset[,1:8],col = "orange",main = "Boxplots for All predictors")
pairs(dataset[,c(1,2,3,6,7)], main = "Pairplot of Important Predictors", col = "blue",lower.panel = NULL)
#Load required libraries
library(ggplot2)
library(reshape)
cormat = cor(dataset[1:8])
cormat
cormat = melt(cor(dataset[1:8]))
cormat
ggplot(data = cormat
,aes(x = X1,y = X2,fill = value))
ggplot(data = cormat
,aes(x = X1,y = X2,fill = value)) + geom_tile()
ggplot(data = cormat
,aes(x = X1,y = X2,fill = value)) + geom_tile() +  scale_x_discrete(labels = function(x) stringr::str_wrap(x, width = 2))
corr.test(dataset[1:8])
?corr.test()
cor.test(dataset[,1], dataset[,2])
cortable = cortable[-1,]
#store dataset
dataset = read.csv("Concrete_Data.csv")
#rename columns of dataset for simplicity
colnames(dataset) = c("Cement","Blast Furnace Slag"," Fly Ash","Water ","Superplasticizer","Coarse Aggregate","Fine Aggregate"," Age (day)","CCS")
#store the dimensions of dataset
n = nrow(dataset)                         #number of instances
p = ncol(dataset) - 1                     #number of predictors
summary(dataset)
summary(dataset)
<hr>
## Visulaization
<hr>
### Histograms
```{r}
par(mfrow = c(3, 3))
for (i in 1:p) {
hist(dataset[,i],'FD',col = "lightblue",main = paste(colnames(dataset)[i]),xlab = colnames(dataset)[i])
abline(v = mean(dataset[,i]) , lty = 2)
}
boxplot(dataset[,1:8],col = "orange",main = "Boxplots for All predictors")
pairs(dataset[,c(1,2,3,6,7)], main = "Pairplot of Important Predictors", col = "blue",lower.panel = NULL)
#Load required libraries
library(ggplot2)
library(reshape)
#calculate correlation and transform it by melt() to make it suitable for ggplot
cormat = melt(cor(dataset[1:8]))
#plot the correlation and adjust width of x labels
ggplot(data = cormat,aes(x = X1,y = X2,fill = value))+
geom_tile()  +                     #creates heatmap
geom_text(aes(label = round(value, 2)), color = "white", size = 4)+                     #Add values inside tiles
scale_x_discrete(labels = function(x) stringr::str_wrap(x, width = 2))                        #Wrap long labels
cortable = NULL
for(i in 1:p)
{
for(j in (i+1):p)
{
test = cor.test(dataset[,i],dataset[,j])
cortable = rbind(cortable,c(colnames(dataset)[i],colnames(dataset)[j],test$estimate,test$conf.int,test$p.value))
}
}
colnames(cortable) <- c("Predictor1", "Predictor2", "Estimate", "Conf_Int_Lower", "Conf_Int_Upper", "p_value")
cortable = cortable[-1,]
library(knitr)
kable(cortable, caption = "Correlation Table with Confidence Intervals")
install.packages("DT")
library(DT)
datatable(cortable, caption = "Correlation Table with Confidence Intervals")
cortable = cortable[-n,]
library(DT)
datatable(cortable, caption = "Correlation Table with Confidence Intervals")
cortable = cortable[-nrow(cortable),]
datatable(cortable, caption = "Correlation Table with Confidence Intervals")
install.packages("rmarkdown")
install.packages("IRkernel")
install.packages("rmarkdown")
getdir()
dir()
getDir()
# load scale file
source("scale.r")
pca_from_correlation = function(X)
{
#extract dimensions of data
n = nrow(X)
p = ncol(X)
#stop if features and cases are less than two
stopifnot("n must be at least 2" = n >= 2)
stopifnot("p must be at least 2" = p >= 2)
# step 1: Scale features
Y = scale(X)
# step 2: compute correlation matrix
C = (t(Y) %*% Y) /  (n-1)
# step 3: eigen eigendecomposition of C
decomposition = eigen(C)
d = decomposition$values
V = decomposition$vectors
# step 4: if eigenvalues not d > 0 stop
stopifnot(all(d > 0))
#------------------------LLM Code-------------------------------------
#Rearrange if eigen values not in descending order
if (!isTRUE(all.equal(d, sort(d, decreasing = TRUE)))) {
idx <- order(d, decreasing = TRUE)  # Find indices for descending sort
d <- d[idx]                         # Reorder eigenvalues
V <- V[, idx]                       # Reorder columns of eigenvectors
}
#----------------------------------------------------------------------
# step 5 :
Scores = Y %*% V    # principal component matrix is Y R.
sdev = sqrt(d)      # Standard deviations of the PCs are the square roots of first k eigenvalues in d.
# create a list
pca = list()
# add outputs to the list
pca[["sdev"]] = sdev
pca[["loadings"]] = V
pca[["scores"]] = Scores
return(pca)
}
scale = function(X)
{
#X: nxp matrix
#n: number of casses
n = nrow(X)
#p: number of features/variables
p = ncol(X)
#Y: Matrix to store scaled data columns
Y = matrix(0,n,p)
#iterate through each columnn
for(i in 1:p)
{
mean_i = mean(X[,i])  # mean of ith columns
sd_i = sd(X[,i])      # standard deviation of ith column
#subtract mean from each entry and divide by standard deviation
for(j in 1:n)
Y[j,i] = (X[j,i] - mean_i) / sd_i
}
return (Y)
}
# load scale file
source("scale.r")
knitr::opts_chunk$set(echo = TRUE)
source("functions/pca_from_correlation.r")
source("functions/pca_from_correlation.r")
source("functions/pca_from_correlation.r")
source("functions/pca_from_correlation.r")
source("functions/pca_from_correlation.r")
source("functions/pca_from_correlation.r")
source("functions/pca_from_correlation.r")
source("functions/pca_from_correlation.r")
source("functions/pca_from_correlation.r")
source("functions/pca_from_svd.r")
source("functions/pca_from_svd.r")
# load scale file
source("scale.r")
source("scale.r")
source("functions/pca_from_svd.r")
source("functions/pca_from_svd.r")
# pca for USArrest dataset
USArrests_pca = pca_from_svd(USArrests)
setwd("D:\data-science\SC562-ML-I")
setwd("D:/data-science/SC562-ML-I")
#c.
model = lm(mpg ~ cylinders+displacement+horsepower+weight+acceleration+year+origin,data = auto[,1:8] )
auto = read.csv("ALL CSV FILES - 2nd Edition/Auto.csv") #load data
#removing ? from all rows
auto[auto == "?"] = NA
auto = na.omit(auto)
#converting horespower to numeric
auto$horsepower = as.numeric(auto$horsepower)
#a.
pairs(auto[,1:8],lower.panel = NULL)
#b.
correlation = cor(auto[,1:8])
#c.
model = lm(mpg ~ cylinders+displacement+horsepower+weight+acceleration+year+origin,data = auto[,1:8] )
summary(model)
#d.
plot(model)
#d.
par(mfrow = c(2,2))
plot(model)
